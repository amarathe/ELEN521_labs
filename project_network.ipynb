{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "project_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amarathe/ELEN521_labs/blob/master/project_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLOdTLE7y9_X",
        "colab_type": "text"
      },
      "source": [
        "# Project: Retinal OCT Images recognition\n",
        "# Sharanjeet Singh, Ashwin Marathe\n",
        "Classify images of retina\n",
        "4 categories: \n",
        "    CNV - Choroidal neovascularization\n",
        "    DME -  Diabetic macular edema \n",
        "    DRUSEN - Multiple drusen\n",
        "    NORMAL - Normal retina\n",
        "\n",
        "84,000 images in dataset\n",
        "    \n",
        "https://www.kaggle.com/paultimothymooney/kermany2018/data#CNV-1016042-2.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gFuv9iV1ttb",
        "colab_type": "code",
        "outputId": "2d0308ba-99d0-41dc-9ded-035c2dfab236",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.optimizers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from IPython.display import Image\n",
        "import pandas as pd\n",
        "import os.path\n",
        "from os import path\n",
        "import glob, os\n",
        "import random\n",
        "\n",
        "BATCHSIZE = 64\n",
        "NSAMPLES = 75000\n",
        "\n",
        "#Instructions for getting dataset from kaggle:\n",
        "# https://medium.com/@saedhussain/google-colaboratory-and-kaggle-datasets-b57a83eb6ef8\n",
        "from google.colab import files\n",
        "!pip install -q kaggle\n",
        "#Upload your kaggle.json API file\n",
        "\n",
        "if not path.exists(\"/root/.kaggle/kaggle.json\"): \n",
        "  firsttime = True\n",
        "  uploaded = files.upload()\n",
        "  !mkdir ~/.kaggle\n",
        "  !mv kaggle.json ~/.kaggle/kaggle.json\n",
        "  !ls -halt ~/.kaggle\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "!kaggle datasets download -d paultimothymooney/kermany2018\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa6c5ab4-1c4f-445f-9a02-15625dbe00e8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-aa6c5ab4-1c4f-445f-9a02-15625dbe00e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "total 16K\n",
            "drwxr-xr-x 2 root root 4.0K Mar 18 23:36 .\n",
            "drwx------ 1 root root 4.0K Mar 18 23:36 ..\n",
            "-rw-r--r-- 1 root root   64 Mar 18 23:36 kaggle.json\n",
            "Downloading kermany2018.zip to /content\n",
            "100% 10.8G/10.8G [04:23<00:00, 71.6MB/s]\n",
            "100% 10.8G/10.8G [04:23<00:00, 44.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ltEwb6y9_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import zipfile\n",
        "if not path.exists(\"kermany2018\"):\n",
        "  with zipfile.ZipFile(\"kermany2018.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"kermany2018\")\n",
        "\n",
        "#!ls kermany2018/OCT2017\\ /train/CNV/ | more\n",
        "#If first time, partition 5% validation data from training data\n",
        "if firsttime:\n",
        "  os.system(\"mv kermany2018/OCT2017\\ /val/ kermany2018/OCT2017\\ /backup_val/\" )\n",
        "  os.system(\"mkdir kermany2018/OCT2017\\ /val\")\n",
        "  for label in [\"CNV\", \"DME\", \"DRUSEN\", \"NORMAL\"]:\n",
        "    files = list(glob.glob(\"kermany2018/OCT2017 /train/\" + label + \"/*.jpeg\"))\n",
        "    random.shuffle(files)\n",
        "    #print (\"glob:\", glob.glob(\"kermany2018/OCT2017 /train/\" + label + \"/*.jpeg\"))\n",
        "    #print (\"files:\", files)\n",
        "    train_files, val_files = files[:int(len(files)*0.95)], files[int(len(files)*0.95):]\n",
        "    os.system(\"mkdir kermany2018/OCT2017\\ /val/\"+label+\"/\")\n",
        "    for file in val_files:\n",
        "      #print (\"Moving file:\", file, \"to: kermany2018/OCT2017\\ /val/\" + label + \"/\")\n",
        "      os.system(\"mv \" + file.replace(\" \", \"\\ \") + \" kermany2018/OCT2017\\ /val/\" + label + \"/\")\n",
        "  firsttime = False\n",
        "\n",
        "#!ls \"kermany2018/OCT2017 \"\n",
        "train_datagen = ImageDataGenerator(rescale=1./256)\n",
        "#valid_datagen = ImageDataGenerator(rescale=1./256)\n",
        "test_datagen = ImageDataGenerator(rescale=1./256)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUwmDxJgMN6M",
        "colab_type": "code",
        "outputId": "29a625b8-1822-44a3-dbcf-cb57025b8df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# load and iterate training dataset\n",
        "train_generator = train_datagen.flow_from_directory('kermany2018/OCT2017 /train/', class_mode='categorical', \n",
        "                                             target_size=(512,512), batch_size=BATCHSIZE)\n",
        "\n",
        "#Only 32 images in validation dataset - too small. Use test train split from train dataset\n",
        "# load and iterate validation dataset\n",
        "#valid_generator = valid_datagen.flow_from_directory('kermany2018/OCT2017 /val/', class_mode='categorical', \n",
        "#                                           target_size=(512,512), batch_size=BATCHSIZE)\n",
        "valid_generator = train_datagen.flow_from_directory('kermany2018/OCT2017 /val/', class_mode='categorical', \n",
        "                                             target_size=(512,512), batch_size=BATCHSIZE)\n",
        "# load and iterate test dataset\n",
        "test_generator = test_datagen.flow_from_directory('kermany2018/OCT2017 /test/', class_mode='categorical', \n",
        "                                           target_size=(512,512), batch_size=BATCHSIZE)\n",
        "\n",
        "#traindf = pd.read_csv('kermany2018.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 79308 images belonging to 4 classes.\n",
            "Found 4176 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_liWkEaJ_V-a",
        "colab_type": "code",
        "outputId": "a5901e7f-7e68-4b26-830c-d06b44b8cddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls kermany2018/OCT2017\\ /val/NORMAL/ | wc -l\n",
        "!ls kermany2018/OCT2017\\ /train/NORMAL/ | wc -l\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1316\n",
            "24999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVnRUYV88Lrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for label in [\"CNV\", \"DME\", \"DRUSEN\", \"NORMAL\"]:\n",
        "\n",
        "#  files = list(glob.glob(\"kermany2018/OCT2017 /train/\" + label + \"/*.jpeg\"))\n",
        "#  random.shuffle(files)\n",
        "#  #print (\"glob:\", glob.glob(\"kermany2018/OCT2017 /train/\" + label + \"/*.jpeg\"))\n",
        "#  #print (\"files:\", files)\n",
        "#  train_files, val_files = files[:int(len(files)*0.95)], files[int(len(files)*0.95):]\n",
        "#  os.system(\"mkdir kermany2018/OCT2017\\ /val/\"+label+\"/\")\n",
        "#  for file in val_files:\n",
        "#    print (\"Moving file:\", file, \"to: kermany2018/OCT2017\\ /val/\" + label + \"/\")\n",
        "#    os.system(\"mv \" + file.replace(\" \", \"\\ \") + \" kermany2018/OCT2017\\ /val/\" + label + \"/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSL42fIxISIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns model and model before last activation (for debug)\n",
        "def get_model():\n",
        "    x = x_in = Input((512,512,3), name=\"input\")\n",
        "    x = Conv2D(8, (3,3), padding=\"same\",  name=\"fe0\")(x)\n",
        "    x = Activation(\"relu\", name=\"r0\")(x)\n",
        "    x = MaxPooling2D(2,2,name=\"mp0\")(x)\n",
        "    x = BatchNormalization(name=\"bn1\")(x)\n",
        "    x = Conv2D(16, (3,3), padding=\"same\", name=\"fe1\")(x)\n",
        "    x = Activation(\"relu\", name=\"r1\")(x)\n",
        " #   x = MaxPooling2D(2,2,name=\"mp1\")(x)\n",
        "    x = BatchNormalization(name=\"bn2\")(x)\n",
        "    x = Conv2D(16, (3,3), padding=\"same\", name=\"fe2\")(x)\n",
        "    x = Activation(\"relu\", name=\"r2\")(x)\n",
        "    x = MaxPooling2D(2,2,name=\"mp2\")(x)\n",
        "    x = BatchNormalization(name=\"bn3\")(x)\n",
        "    x = Conv2D(32, (3,3), padding=\"same\", name=\"fe3\")(x)\n",
        "    x = Activation(\"relu\", name=\"r3\")(x)\n",
        "    x = BatchNormalization(name=\"bn4\")(x)\n",
        "    x = Conv2D(32, (3,3), padding=\"same\", name=\"fe4\")(x)\n",
        "    x = Activation(\"relu\", name=\"r4\")(x)\n",
        "    x = MaxPooling2D(2,2,name=\"mp3\")(x)   \n",
        "    x = Dropout(0.5, name=\"d0\")(x)\n",
        "    x = Flatten(name=\"fl\")(x)\n",
        "    #x = Dense(64, name=\"d0\", activation=\"relu\")(x)\n",
        "    x = Dense(4, name=\"d1\")(x)\n",
        "    x = x_int = Activation(\"softmax\", name=\"s1\")(x)\n",
        "    m = Model(inputs=x_in, outputs=x)\n",
        "    m_int = Model(inputs=x_in, outputs=x_int)\n",
        "    m.summary()\n",
        "    return m, m_int\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nle43bsmJxdR",
        "colab_type": "code",
        "outputId": "982b5af8-923c-4cdf-c8ad-3f7e661036c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model, model_int = get_model()\n",
        "adam = Adam(lr=0.0001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"acc\"])\n",
        "\n",
        "result = model.evaluate_generator(test_generator)\n",
        "print (\"Test results with random weights - should be 25%: Accuracy\", result[1])\n",
        "print (\"\\t Loss:\", result[0])\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=NSAMPLES//BATCHSIZE, # number of times it executes until it declares epoch is over.\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=NSAMPLES//(4*BATCHSIZE))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 512, 512, 3)       0         \n",
            "_________________________________________________________________\n",
            "fe0 (Conv2D)                 (None, 512, 512, 8)       224       \n",
            "_________________________________________________________________\n",
            "r0 (Activation)              (None, 512, 512, 8)       0         \n",
            "_________________________________________________________________\n",
            "mp0 (MaxPooling2D)           (None, 256, 256, 8)       0         \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 256, 256, 8)       32        \n",
            "_________________________________________________________________\n",
            "fe1 (Conv2D)                 (None, 256, 256, 16)      1168      \n",
            "_________________________________________________________________\n",
            "r1 (Activation)              (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 256, 256, 16)      64        \n",
            "_________________________________________________________________\n",
            "fe2 (Conv2D)                 (None, 256, 256, 16)      2320      \n",
            "_________________________________________________________________\n",
            "r2 (Activation)              (None, 256, 256, 16)      0         \n",
            "_________________________________________________________________\n",
            "mp2 (MaxPooling2D)           (None, 128, 128, 16)      0         \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 128, 128, 16)      64        \n",
            "_________________________________________________________________\n",
            "fe3 (Conv2D)                 (None, 128, 128, 32)      4640      \n",
            "_________________________________________________________________\n",
            "r3 (Activation)              (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "fe4 (Conv2D)                 (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "r4 (Activation)              (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "mp3 (MaxPooling2D)           (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "d0 (Dropout)                 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "fl (Flatten)                 (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "d1 (Dense)                   (None, 4)                 524292    \n",
            "_________________________________________________________________\n",
            "s1 (Activation)              (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 542,180\n",
            "Trainable params: 542,036\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Test results with random weights - should be 25%: Accuracy 0.24793388429752067\n",
            "\t Loss: 1.3862110130057848\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "1171/1171 [==============================] - 771s 659ms/step - loss: 1.1682 - acc: 0.6258 - val_loss: 0.6331 - val_acc: 0.7644\n",
            "Epoch 2/20\n",
            "1171/1171 [==============================] - 756s 645ms/step - loss: 0.5725 - acc: 0.7912 - val_loss: 0.5075 - val_acc: 0.8156\n",
            "Epoch 3/20\n",
            "1171/1171 [==============================] - 727s 621ms/step - loss: 0.4559 - acc: 0.8350 - val_loss: 0.4446 - val_acc: 0.8340\n",
            "Epoch 4/20\n",
            "1171/1171 [==============================] - 746s 637ms/step - loss: 0.3916 - acc: 0.8583 - val_loss: 0.4426 - val_acc: 0.8454\n",
            "Epoch 5/20\n",
            "1171/1171 [==============================] - 741s 633ms/step - loss: 0.3394 - acc: 0.8771 - val_loss: 0.3970 - val_acc: 0.8604\n",
            "Epoch 6/20\n",
            "1171/1171 [==============================] - 738s 630ms/step - loss: 0.2936 - acc: 0.8938 - val_loss: 0.3739 - val_acc: 0.8718\n",
            "Epoch 7/20\n",
            " 411/1171 [=========>....................] - ETA: 6:59 - loss: 0.2843 - acc: 0.8982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a663879becb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     validation_steps=NSAMPLES//(4*BATCHSIZE))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS2fCNFMUy1C",
        "colab_type": "code",
        "outputId": "146da407-c331-448a-aac8-49e152f3b247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#for data_batch, labels_batch in train_generator:\n",
        "#  prediction = model.predict(data_batch)\n",
        "#  print (\"Prediction:\", prediction)\n",
        "#  print (\"labels:\", labels_batch)\n",
        "#  break\n",
        "\n",
        "result = model.evaluate_generator(test_generator)\n",
        "print (\"Test results: Accuracy\", result[1])\n",
        "print (\"\\t Loss:\", result[0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test results: Accuracy 0.8099173553719008\n",
            "\t Loss: 0.47965191760339027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0m1WOn8oBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plothistory(history):\n",
        "  # Plot training & validation accuracy values\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uctlqo0P8szr",
        "colab_type": "code",
        "outputId": "0ca8ed81-6a81-44bd-fd16-bc33f328b528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "plothistory(history)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-14d64f5bb825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplothistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcwrSHX4y9_g",
        "colab_type": "text"
      },
      "source": [
        "Use VGG16 and train last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJk6rex0bvq7",
        "colab_type": "code",
        "outputId": "9261c4e3-d375-4bc7-8465-d05e3c7a9eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pixels = 128\n",
        "\n",
        "# load and iterate training dataset\n",
        "train_generator = train_datagen.flow_from_directory('kermany2018/OCT2017 /train/', class_mode='categorical', \n",
        "                                             target_size=(pixels,pixels), batch_size=BATCHSIZE)\n",
        "\n",
        "#Only 32 images in validation dataset - too small. Use test train split from train dataset\n",
        "# load and iterate validation dataset\n",
        "#valid_generator = valid_datagen.flow_from_directory('kermany2018/OCT2017 /val/', class_mode='categorical', \n",
        "#                                           target_size=(512,512), batch_size=BATCHSIZE)\n",
        "valid_generator = train_datagen.flow_from_directory('kermany2018/OCT2017 /val/', class_mode='categorical', \n",
        "                                             target_size=(pixels,pixels), batch_size=BATCHSIZE)\n",
        "# load and iterate test dataset\n",
        "test_generator = test_datagen.flow_from_directory('kermany2018/OCT2017 /test/', class_mode='categorical', \n",
        "                                           target_size=(pixels,pixels), batch_size=BATCHSIZE)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 79308 images belonging to 4 classes.\n",
            "Found 4176 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BNh7S7My-AO",
        "colab_type": "code",
        "outputId": "fff18337-d6a0-4b4d-a402-396cf1ade01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
        "vgg16.summary()\n",
        "\n",
        "for layer in vgg16.layers[:-4]:\n",
        "  layer.trainable=False\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "  print (layer, layer.trainable)\n",
        "\n",
        "#x_i = Input((150, 150, 3), name=\"input\")\n",
        "x_i = Input((pixels,pixels,3), name=\"input\")\n",
        "x = vgg16(x_i)\n",
        "x = Flatten(name=\"fl\")(x)\n",
        "x = Dropout(0.5, name=\"d5\")(x)\n",
        "x = Dense(64, name=\"d1\", activation=\"relu\")(x)\n",
        "x = Dense(4, name=\"d2\", activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=x_i, outputs=x)\n",
        "model.summary()\n",
        "\n",
        "#adam = Adam(lr=0.001)\n",
        "adam = Adam(lr=0.0001)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"acc\"])\n",
        "\n",
        "NSAMPLES = 10000\n",
        "NUM_EPOCHS=5\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=NSAMPLES//100, # number of times it executes until it declares epoch is over.\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=NSAMPLES//(2*100))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fe6f8b22f28> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fb6df278> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6f8b1b198> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe6f8b1bda0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fb6f5c50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6facf94a8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe6facfd208> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6f8b1c940> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6f8b20a58> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6f8b217b8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe6fa3fa240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa401860> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa40c978> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa4136d8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe6fa4250b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa42c6d8> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa3c7860> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe6fa3ba5c0> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe6fa3cd5c0> True\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "fl (Flatten)                 (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "d5 (Dropout)                 (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "d1 (Dense)                   (None, 64)                524352    \n",
            "_________________________________________________________________\n",
            "d2 (Dense)                   (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 15,239,300\n",
            "Trainable params: 7,604,036\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "100/100 [==============================] - 37s 371ms/step - loss: 0.2974 - acc: 0.8763 - val_loss: 0.1931 - val_acc: 0.9219\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.2037 - acc: 0.9200 - val_loss: 0.1647 - val_acc: 0.9386\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.1736 - acc: 0.9337 - val_loss: 0.1564 - val_acc: 0.9420\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.1564 - acc: 0.9396 - val_loss: 0.1576 - val_acc: 0.9410\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.1485 - acc: 0.9452 - val_loss: 0.1443 - val_acc: 0.9444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So8DalNPZQ5g",
        "colab_type": "code",
        "outputId": "58a1b0fd-a911-403d-b3a9-7e3d488ec260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "result = model.evaluate_generator(test_generator)\n",
        "print (\"Test results: Accuracy\", result[1])\n",
        "print (\"\\t Loss:\", result[0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test results: Accuracy 0.9759814049586777\n",
            "\t Loss: 0.08266070232657362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNp_GzlJU5W9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "1d323ed9-adcb-45e8-e0e8-52b804e08207"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "#Get Precision, recall, F1 score\n",
        "num2losses = {0: \"CNV\", 1: \"DME\", 2: \"DRUSEN\", 3: \"NORMAL\"}\n",
        "\n",
        "#Get test/train data from generator\n",
        "xtest, ytest = [],[]\n",
        "max_iter = 2000\n",
        "i = 0\n",
        "for x, y in test_generator:\n",
        "    for j in range(x.shape[0]):\n",
        "      xtest.append(x[j])\n",
        "      ytest.append(y[j])\n",
        "      i += 1\n",
        "    if i >= max_iter:\n",
        "        break\n",
        "\n",
        "xtest = np.array(xtest)\n",
        "ytest = np.array(ytest)\n",
        "print (\"x shape:\", xtest.shape)\n",
        "print (\"y shape:\", ytest.shape)\n",
        "\n",
        "# From https://www.kaggle.com/chestnut111/new-vgg-model-transfer-for-retina-oct-data-0-96\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (5,5))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "y_pred = model.predict(xtest)\n",
        "print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(num2losses.values())), sep='') \n",
        "Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
        "Y_true = np.argmax(ytest,axis = 1) \n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "\n",
        "plot_confusion_matrix(confusion_mtx, classes = list(num2losses.values()))\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x shape: (2000, 128, 128, 3)\n",
            "y shape: (2000, 4)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         CNV       0.92      1.00      0.96       504\n",
            "         DME       1.00      0.93      0.97       491\n",
            "      DRUSEN       1.00      0.89      0.94       498\n",
            "      NORMAL       0.93      1.00      0.96       507\n",
            "\n",
            "    accuracy                           0.96      2000\n",
            "   macro avg       0.96      0.96      0.96      2000\n",
            "weighted avg       0.96      0.96      0.96      2000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAFdCAYAAADIezyPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}